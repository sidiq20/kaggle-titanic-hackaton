# Titanic Survival Prediction

#### This project predicts whether a passenger survived the Titanic disaster using machine learning models. The dataset used in this project is based on Kaggle'sTitanic: Machine Learning from Disaster competition.

## The project covers:

1. Data Preprocessing (cleaning, encoding, and handling missing values)
2. Feature Engineering (creating new features)
3. Hyperparameter Tuning
4. Model Evaluation and Validation
5. Ensemble Learning (Voting Classifier)

## Installation

1. Clone the repository or download the code files.

2. Ensure you have Python installed (preferably 3.8 or higher).

3. Install the required libraries using:


    pip install -r requirements.txt

## Requirements

The project requires the following Python libraries:

1. pandas
2. scikit-learn
3. numpy

You can install them using the provided requirements.txt or manually by running:

    pip install pandas scikit-learn numpy


## Project Files

1. train.csv : Training dataset (from Kaggle)
2. tested.csv : Test dataset (from Kaggle)
3. titanic_prediction.py : Python script for loading data, training models, and generating predictions.
4. README.md : Project overview and instructions.
5. submission.csv : Final submission file with predicted survival values (generated by the script).


## Data Preprocessing

The data preprocessing steps include:

Encoding categorical features like Sex and Embarked.

Imputation of missing values in Age and Fare using the median.

Feature Engineering: Creation of a new feature, FamilySize, and extraction of Title from the Name column.

## The final features used for training are:

Pclass: Passenger Class (1st, 2nd, 3rd)

Sex: Gender of the passenger

Age: Age of the passenger

SibSp: Number of siblings/spouses aboard

Parch: Number of parents/children aboard

Fare: Ticket fare

Embarked: Port of embarkation

FamilySize: Total number of family members aboard

Title: Title extracted from the name (e.g., Mr, Miss, Mrs)


## Models Used
The project utilizes the following machine learning models:

1. Logistic Regression: A simple linear model used for binary classification.

2. Random Forest Classifier: An ensemble method that trains multiple decision trees and averages their predictions.

3. Gradient Boosting Classifier: Another ensemble method that builds models sequentially to minimize errors.

4. Voting Classifier: A combination of the above three models where each model "votes" for the final prediction.